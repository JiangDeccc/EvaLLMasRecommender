{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paras\n",
    "dataset = 'sports'\n",
    "dataset_text = 'Sports'\n",
    "# history = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input data\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user2id', 'item2id', 'id2user', 'id2item', 'attribute2id', 'id2attribute', 'attributeid2num'])\n"
     ]
    }
   ],
   "source": [
    "f = open(f'../../llm_results/{dataset}/datamaps.json', 'r')\n",
    "content = f.read()\n",
    "data_maps = json.loads(content)\n",
    "print(data_maps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35598\n"
     ]
    }
   ],
   "source": [
    "file = open(f\"../../llm_results/{dataset}/sequential_data.txt\", 'r')\n",
    "test_samples = []\n",
    "for line in file.readlines():\n",
    "    test_samples.append(line[:-1])\n",
    "file.close()\n",
    "print(len(test_samples))\n",
    "test_samples = [x.split(' ') for x in test_samples]\n",
    "# 1: user_id; 2-n: user_history item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35598\n"
     ]
    }
   ],
   "source": [
    "file = open(f\"../../llm_results/{dataset}/negative_samples.txt\", 'r')\n",
    "negative_samples = []\n",
    "for line in file.readlines():\n",
    "    negative_samples.append(line[:-1])\n",
    "file.close()\n",
    "print(len(negative_samples))\n",
    "negative_samples = [x.split(' ') for x in negative_samples]\n",
    "# 1: user_id; 2-n: negative sample item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"../../llm_results/{dataset}/meta.json\", 'r')\n",
    "metas = json.load(file)\n",
    "metas = metas.split('\\n')[:-1]\n",
    "metas = [eval(x) for x in metas]\n",
    "for item in metas:\n",
    "    try:\n",
    "        _ = (item['asin'], item['title'])\n",
    "    except:\n",
    "        item['title'] = 'N\\A'\n",
    "        \n",
    "item_asin2name = [(x['asin'], x['title']) for x in metas]\n",
    "item_asin2name = {key: value for key, value in item_asin2name}\n",
    "# item_title2categories = [(x['title'], x['categories'][0][1:]) for x in metas]\n",
    "# item_title2categories = {key: value for key, value in item_title2categories}\n",
    "\n",
    "def item_id2title(x):\n",
    "    asin = data_maps['id2item'][x]\n",
    "    return item_asin2name[asin]\n",
    "item_id2name = [(x, item_id2title(x)) for x in data_maps['id2item'].keys()]\n",
    "item_id2name = {key: value for key, value in item_id2name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2item_id = [(item_asin2name[data_maps['id2item'][x]], x) for x in data_maps['id2item'].keys()]\n",
    "name2item_id = {key: value for key, value in name2item_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_path = f'../../llm_results/{dataset}/user_id2name.pkl'\n",
    "username = np.load(username_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate prompt from templates\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template.txt / template_wohistory.txt\n",
    "# zero-shot instruction construction (history/candidate shuffled)\n",
    "# template_user_profile.txt / template_profile_history.txt\n",
    "# zero-shot instruction construction with user profile (without user history)\n",
    "def generate_zero_shot_prompt(user_id, prompt, dataset_name, his_len, cand_len, his_shuffle=False, cand_shuffle=True, cand_list_id=[]):\n",
    "    a_user_history = test_samples[int(user_id)-1][1:-1]\n",
    "    a_user_history = [item_id2name[x] for x in a_user_history]\n",
    "    if len(a_user_history) > his_len:\n",
    "        a_user_history = a_user_history[-his_len:]\n",
    "    # whether to random shuffle user history\n",
    "    if his_shuffle:\n",
    "        random.shuffle(a_user_history)\n",
    "    if len(cand_list_id) == 0:\n",
    "        cand_list_id = [test_samples[int(user_id)-1][-1]] + negative_samples[int(user_id)-1][1:cand_len]\n",
    "        # whether to random shuffle candidate list\n",
    "        if cand_shuffle:\n",
    "            random.shuffle(cand_list_id)\n",
    "    cand_list = [item_id2name[x] for x in cand_list_id]\n",
    "    target = item_id2name[test_samples[int(user_id)-1][-1]]\n",
    "    rtn_prompt = prompt.replace('{user_name}', username[str(user_id)])\n",
    "    rtn_prompt = rtn_prompt.replace('{user_history}', str(a_user_history))\n",
    "    rtn_prompt = rtn_prompt.replace('{candidate_list}', str(cand_list))\n",
    "    rtn_prompt = rtn_prompt.replace('{dataset}', str(dataset_name))\n",
    "    rtn_prompt = rtn_prompt.replace('\\\"', '\\'')\n",
    "    return rtn_prompt, target, cand_list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_user_profile_generate.txt\n",
    "# user profile generation\n",
    "def generate_user_profile_prompt(user_id, prompt, dataset_name, his_len):\n",
    "    a_user_history = test_samples[int(user_id)-1][1:-1]\n",
    "    a_user_history = [item_id2name[x] for x in a_user_history]\n",
    "    if len(a_user_history) > his_len:\n",
    "        a_user_history = a_user_history[-his_len:]\n",
    "    target = item_id2name[test_samples[int(user_id)-1][-1]]\n",
    "    rtn_prompt = prompt.replace('{user_name}', username[str(user_id)])\n",
    "    rtn_prompt = rtn_prompt.replace('{user_history}', str(a_user_history))\n",
    "    rtn_prompt = rtn_prompt.replace('{dataset}', str(dataset_name))\n",
    "    rtn_prompt = rtn_prompt.replace('\\\"', '\\'')\n",
    "    return rtn_prompt, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_in_context.txt\n",
    "# in-context learning instructions (last item reinforced)\n",
    "def generate_in_context_prompt(user_id, prompt, dataset_name, his_len, cand_len, his_shuffle=False, cand_shuffle=True, cand_list_id=None):\n",
    "    a_user_history = test_samples[int(user_id)-1][1:-1]\n",
    "    a_user_history = [item_id2name[x] for x in a_user_history]\n",
    "    if len(a_user_history) > his_len:\n",
    "        a_user_history = a_user_history[-his_len:]\n",
    "    # whether to random shuffle user history\n",
    "    if his_shuffle:\n",
    "        random.shuffle(a_user_history)\n",
    "    if cand_list_id == None:\n",
    "        cand_list_id = [test_samples[int(user_id)-1][-1]] + negative_samples[int(user_id)-1][1:cand_len]\n",
    "        # whether to random shuffle candidate list\n",
    "        if cand_shuffle:\n",
    "            random.shuffle(cand_list_id)\n",
    "    cand_list = [item_id2name[str(x)] for x in cand_list_id]\n",
    "    target = item_id2name[test_samples[int(user_id)-1][-1]]\n",
    "    rtn_prompt = prompt.replace('{user_name}', username[str(user_id)])\n",
    "    rtn_prompt = rtn_prompt.replace('{user_history}', str(a_user_history))\n",
    "    rtn_prompt = rtn_prompt.replace('{last_history}', str(a_user_history[:-1]))\n",
    "    rtn_prompt = rtn_prompt.replace('{last_item}', \"[\\'\"+str(a_user_history[-1])+\"\\']\")\n",
    "    rtn_prompt = rtn_prompt.replace('{candidate_list}', str(cand_list))\n",
    "    rtn_prompt = rtn_prompt.replace('{dataset}', str(dataset_name))\n",
    "    rtn_prompt = rtn_prompt.replace('\\\"', '\\'')\n",
    "    return rtn_prompt, target, cand_list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_template(template_file):\n",
    "    file = open(template_file, 'r')                                      \n",
    "    templates = []\n",
    "    for line in file.readlines():\n",
    "        templates.append(line[:-1])\n",
    "    file.close()\n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demonstration_prompts(user_ids, target_user, template_num, dataset_name, history):\n",
    "    demo_templates = read_template('./templates/template_demonstration.txt')\n",
    "    example_prompts = []\n",
    "    for user_id in user_ids:\n",
    "        prompt_str = \"Here\\'s a demonstration example:\\n\"\n",
    "        demo, target, _ = generate_zero_shot_prompt(str(user_id), demo_templates[template_num], dataset_name, history, 20)\n",
    "        prompt_str += demo + \"\\n\"\n",
    "        prompt_str = prompt_str.replace('{target}', \"[\\'\"+target+\"\\']\")\n",
    "        # prompt_str += \"Do you think the pattern of the demonstration example is helpful for you to generate more accurate recommendation for {user}? If it is helpful, make some changes to improve your top-10 recommendation list to user {user}. If you don't think the example is helpful, then just keep the original answer. Still remember that the output format should be a python list of items' titles.\"\n",
    "        prompt_str += \"Please try to make some changes to improve the recommendation to {user}. Still remember that the output format should be a python list of items' titles.\"\n",
    "        prompt_str = prompt_str.replace('{user}', username[target_user])\n",
    "        example_prompts.append(prompt_str)\n",
    "    return example_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demonstration_prompts_1round(user_ids, target_user, template_num, dataset_name, history):\n",
    "    demo_templates = read_template('./templates/template_demonstration.txt')\n",
    "    example_prompts = []\n",
    "    prompt_str = \"Here\\'s some demonstration examples:\\n\"\n",
    "    for user_id in user_ids:\n",
    "        demo, target, _ = generate_zero_shot_prompt(str(user_id), demo_templates[template_num], dataset_name, history, 20)\n",
    "        prompt_str += demo + \"\\n\"\n",
    "        prompt_str = prompt_str.replace('{target}', \"[\\'\"+target+\"\\']\")\n",
    "    prompt_str += \"Do you think the pattern of the demonstration examples are helpful for you to generate more accurate recommendation for {user}? If they are helpful, make some changes to improve your top-10 recommendation list to user {user}. If you don't think the example is helpful, then just keep the original answer. Still remember that the output format should be a python list of items' titles.\"\n",
    "    # prompt_str += \"Please try to make some changes to improve the recommendation to {user}. Still remember that the output format should be a python list of items' titles.\"\n",
    "    prompt_str = prompt_str.replace('{user}', username[target_user])\n",
    "        # example_prompts.append(prompt_str)\n",
    "    return prompt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# 0: 10 history & candidate random shuffled\n",
    "# 1: 10 history\n",
    "# 2: 10 history & history random shuffled & candidate random shuffled\n",
    "# 3: 10 history user profile generation\n",
    "# 4: 10 history in context & candidate random shuffled\n",
    "# 5: 15 history & candidate random shuffled\n",
    "# 6: 20 history & candidate random shuffled\n",
    "# 7: 10 history & 5-shot examples & candidate random shuffled\n",
    "def generate_prompt(sample_file, dataset_name, templates_file, history=10, task_list=[0,1,2,3], cand_len=20, base_file=None, users=None):\n",
    "    with open(sample_file, 'r') as f:\n",
    "        sample = eval(f.readline())\n",
    "    samples = sorted(sample)\n",
    "    # with open(f'results/{dataset}/sample_1k_all.txt', 'r') as f:\n",
    "    #     content = f.readlines()\n",
    "    # samples = [x[:-1] for x in content]\n",
    "    samples = np.array(samples).astype(str)\n",
    "\n",
    "    gen_base_input = []\n",
    "\n",
    "    if base_file != None:\n",
    "        f = open(base_file, 'r')\n",
    "        content = f.read()\n",
    "        f.close()\n",
    "        gen_base_input = json.loads(content)\n",
    "        if 0 in task_list:\n",
    "            gen_input = []\n",
    "            templates = read_template(templates_file[0])\n",
    "            for i in range(len(samples)):\n",
    "                template_num = random.randint(0, len(templates)-1)\n",
    "                prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, cand_len, cand_list_id=eval(gen_base_input[i]['cand_list']))\n",
    "                gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "            with open(f'results/{dataset_name}/test_history{history}_candidate{cand_len}_shuffle_sample.json', 'w') as file:\n",
    "                json.dump(gen_input, file, indent=4)\n",
    "    else:\n",
    "        if 0 in task_list:\n",
    "            templates = read_template(templates_file[0])\n",
    "            for i in range(len(samples)):\n",
    "                template_num = random.randint(0, len(templates)-1)\n",
    "                prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, cand_len)\n",
    "                gen_base_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "            with open(f'results/{dataset_name}/test_history{history}_candidate{cand_len}_shuffle_sample.json', 'w') as file:\n",
    "                json.dump(gen_base_input, file, indent=4)\n",
    "        else:\n",
    "            raise ValueError\n",
    "    if not gen_base_input:\n",
    "        print('Baseline unexisted.')\n",
    "\n",
    "    if 1 in task_list:\n",
    "        gen_input = []\n",
    "        templates = read_template(templates_file[2])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, len(templates)-1)\n",
    "            prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, cand_len, cand_shuffle=False)\n",
    "            gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "        with open(f'results/{dataset_name}/test_history{history}_candidate{cand_len}_sample.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)\n",
    "    if 2 in task_list:\n",
    "        gen_input = []\n",
    "        templates = read_template(templates_file[2])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, len(templates)-1)\n",
    "            prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, cand_len, his_shuffle=True, cand_list_id=eval(gen_base_input[i]['cand_list']))\n",
    "            gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "        with open(f'results/{dataset_name}/test_history{history}_shuffle_candidate{cand_len}_shuffle_sample.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)\n",
    "    if 3 in task_list:\n",
    "        gen_input = []\n",
    "        templates = read_template(templates_file[3])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, len(templates)-1)\n",
    "            prompt, target = generate_user_profile_prompt(samples[i], templates[template_num], dataset_text, history)\n",
    "            gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'template': template_num})\n",
    "        with open(f'results/{dataset_name}/test_history{history}_generate_profile_sample_1k.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)\n",
    "    if 4 in task_list:\n",
    "        gen_input = []\n",
    "        templates = read_template(templates_file[4])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, len(templates)-1)\n",
    "            prompt, target, cand_list = generate_in_context_prompt(samples[i], templates[template_num], dataset_text, history, cand_len, cand_list_id=eval(gen_base_input[i]['cand_list']))\n",
    "            gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "        with open(f'results/{dataset_name}/test_history{history}_candidate{cand_len}_in_context_sample.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)\n",
    "    if 5 in task_list:\n",
    "        gen_input = gen_base_input[:]\n",
    "        templates = read_template(templates_file[8])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, len(templates)-1)\n",
    "            prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, cand_len, cand_list_id=eval(gen_base_input[i]['cand_list']))\n",
    "            if users == None:\n",
    "                random_numbers = [random.randint(1, len(test_samples)) for _ in range(5)]\n",
    "                while int(samples[i]) in random_numbers:\n",
    "                    random_numbers = [random.randint(1, len(test_samples)) for _ in range(5)]\n",
    "            else:\n",
    "                random_numbers = [sample[x] for x in users[i]]\n",
    "            few_shot_prompts = generate_demonstration_prompts_1round(random_numbers, samples[i], template_num, dataset_text)\n",
    "            gen_input[i]['few_shot'] = [few_shot_prompts]\n",
    "            # gen_input[i]['prompt'] = few_shot_prompts[0] + prompt\n",
    "        with open(f'results/{dataset_name}/test_history{history}_candidate{cand_len}_few_shots_sample_{bool(users)}_1round_prompt.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_file = ['../templates/template.txt', '../templates/template.txt', '../templates/template.txt', '../templates/template_user_profile_generate.txt', \n",
    "                  '../templates/template_in_context.txt', '../template_fewshot.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt(f'./results/{dataset}/sample.txt', dataset, templates_file, np.arange(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval model\n",
    "import pandas as pd\n",
    "# with open(f'./results/{dataset}/sample.txt', 'r') as f:\n",
    "#     sample = eval(f.readline())\n",
    "# samples = sorted(sample)\n",
    "with open(f'results/{dataset}/sample_1k_all.txt', 'r') as f:\n",
    "    content = f.readlines()\n",
    "samples = [x[:-1] for x in content]\n",
    "test_len = 1000\n",
    "def read_sota_results(dataset, model, sample, history_max, shuffle):\n",
    "    df = pd.read_csv(f'./dataset/{dataset}/rec-{model}-{history_max}-{shuffle}-all.csv', sep='\\t')\n",
    "    results_dict = df.set_index('user_id')['rec_items'].to_dict()\n",
    "    # print(results_dict)\n",
    "    id_results = list(map(lambda x: eval(results_dict[int(x)]), sample))\n",
    "    return id_results\n",
    "results_of_models = []\n",
    "results_of_models.append(read_sota_results(dataset+'_100', 'SASRec', samples, 10, False))\n",
    "results_of_models.append(read_sota_results(dataset+'_100', 'GRU4Rec', samples, 10, False))\n",
    "results_of_models.append(read_sota_results(dataset+'_100', 'LightGCN', samples, 20, False))\n",
    "results_of_models.append(read_sota_results(dataset+'_100', 'BPRMF', samples, 20, False))\n",
    "def sample_mult_cands(model_results):\n",
    "    cnt = 0\n",
    "    ptr = 0\n",
    "    pos = 0\n",
    "    cands = []\n",
    "    while cnt < 20:\n",
    "        if model_results[ptr][pos] not in cands:\n",
    "            cands.append(model_results[ptr][pos])\n",
    "            cnt += 1\n",
    "        if ptr % len(results_of_models) == len(results_of_models)-1:\n",
    "            pos += 1\n",
    "        ptr = (ptr+1)%len(results_of_models)\n",
    "    return cands\n",
    "cands_multi_model = [sample_mult_cands([x[i] for x in results_of_models]) for i in range(test_len)]\n",
    "cands_multi_model = np.array(cands_multi_model).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 10\n",
    "samples = np.array(samples).astype(str)\n",
    "gen_input = []\n",
    "templates = read_template('./template.txt')\n",
    "for i in range(len(samples)):\n",
    "    template_num = random.randint(0, 4)\n",
    "    prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, 20, cand_list_id=cands_multi_model[i])\n",
    "    gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(list(cand_list)), 'template': template_num})\n",
    "with open(f'results/{dataset}/test_history{history}_multi_candidate20_shuffle_sample.json', 'w') as file:\n",
    "    json.dump(gen_input, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillSummary(text):\n",
    "    sentences = text.split('\\n')\n",
    "    overall = sentences[-1]\n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task:\n",
    "# 0: history+profile\n",
    "# 1: profile\n",
    "def inject_profile_prompt(sample_file, model, templates_file, history, task_list=[0, 1], sample_cand_list=None):\n",
    "    # with open(sample_file, 'r') as f:\n",
    "    #     sample = eval(f.readline())\n",
    "    # samples = sorted(sample)\n",
    "    with open(f'results/{dataset}/sample_1k_all.txt', 'r') as f:\n",
    "        content = f.readlines()\n",
    "    samples = [x[:-1] for x in content]\n",
    "    samples = np.array(samples).astype(str)\n",
    "    with open(f'results/{dataset}/test_history{history}_generate_profile_sample_texts_{model}.json', 'r') as f:\n",
    "        content = f.read()\n",
    "        texts = json.loads(content)\n",
    "    user2profile = [(x['user'], x['result']) for x in texts]\n",
    "    user2profile = {k:v for (k, v) in user2profile}\n",
    "    if 0 in task_list:\n",
    "        gen_input = []\n",
    "        templates = read_template(templates_file[0])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, 4)\n",
    "            prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, 20, cand_list_id=sample_cand_list[i])\n",
    "            prompt = prompt.replace('{user_profile}', \"\\'\"+distillSummary(user2profile[int(samples[i])])+\"\\'\")\n",
    "            gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "        with open(f'results/{dataset}/test_history{history}_multi_candidate20_shuffle_profile_{model}_history_sample_1k.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)\n",
    "    if 1 in task_list:\n",
    "        gen_input = []\n",
    "        templates = read_template(templates_file[1])\n",
    "        for i in range(len(samples)):\n",
    "            template_num = random.randint(0, 4)\n",
    "            prompt, target, cand_list = generate_zero_shot_prompt(samples[i], templates[template_num], dataset_text, history, 20, cand_list_id=sample_cand_list[i])\n",
    "            prompt = prompt.replace('{user_profile}', \"\\'\"+distillSummary(user2profile[int(samples[i])])+\"\\'\")\n",
    "            gen_input.append({'prompt': prompt, 'target': target, 'user': samples[i], 'cand_list': str(cand_list), 'template': template_num})\n",
    "        with open(f'results/{dataset}/test_history{history}_multi_candidate20_shuffle_profile_{model}_sample_1k.json', 'w') as file:\n",
    "            json.dump(gen_input, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./results/{dataset}/test_history{history}_candidate20_shuffle_sample.json', 'r') as f:\n",
    "    content = f.read()\n",
    "    prompts = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_templates_file = ['./templates/template_profile_history.txt', './templates/template_user_profile.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt4'\n",
    "inject_profile_prompt(f'./results/{dataset}/sample.txt', model_name, profile_templates_file, history, sample_cand_list=cands_multi_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
